---
title: "Neural Network"
date: 2023-10-18T00:00:00-04:00
categories:
  - Project
tags:
  - Machine Learning
  - Python

---

 In this project from UC Berkeley's CS189 (Introduction to Machine Learning), we built a neural network from scratch. 

 Before we even started coding, we had to really understand the math (and biology) fundamental to how neural networks operate. Like all machine learning models, a neural network relies on optimizing a constraint called loss -- the less loss, the better your model performs. In order to reduce loss, we take the gradient (essentially a derivative) of the loss function and adjust our model accordingly. However, this process might need to happen hundreds or thousands of times before , and neural networks


 In order to reduce this high computational workload, neural networks use a mathematical technique called backpropagation. Similar to the chain rule from calculus, the gradient of each   

 ![Math](/assets/images/posts/neural-network)

